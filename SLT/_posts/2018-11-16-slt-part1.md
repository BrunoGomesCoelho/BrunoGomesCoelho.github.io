---
title: "Notes SLT Part 1"
date: 2018-11-16
tags: [machine learning, SLT]
header:
  image: "/images/icmc.jpg"
excerpt: "Notes from the beginning to chapter 3 of the paper 'Statistical Learning Theory: Models, Concepts, and Results'"
mathjax: "true"
--- 

This paper gives a general view of the statistical learning field, which tries to formalize knowledge, garantes and assumptions used in machine learning. Without further ado, let's get to it.





# Introduction and history
Statistical learning theory (or SLT for short) is a old field, originating in the 1960s in western Europe. The general ["father"](http://uk.businessinsider.com/facebook-just-hired-the-father-of-statistical-learning-theory-2014-11) of the field is considered to be Vladimir Vapnik, a soviet (and later american) mathematician. If you recognize his name, that is because Vapnik is also the co-inventor of Support Vector Machines (SVMs), having writen his first paper on them in the 1960 and developing the [kernel trick](https://towardsdatascience.com/understanding-the-kernel-trick-e0bc6112ef78) in the 1990s. In the coming years, he also wrote [varios](https://link.springer.com/article/10.1007/BF00994018) [papers](https://www.springer.com/us/book/9780387987804) and [books](https://www.amazon.com/Statistical-Learning-Theory-Vladimir-Vapnik/dp/0471030031) on SLT; Needless to say, his contribution to machine learning and SLT has been imense.




# The general framework of SLT
The whole idea behind "learning" tasks is to be able to infer a more general rule, that simultaneously explains past experiences and correctly classifies new examples. 

We are mentioning classification only since that is the general focus of the paper, more specifically binary classification, where we only have 2 possibles classes (which will we consider +1 and -1 from here on). We will also only consider supervised learning problems (read [this]({% post_url ML4u/2018-11-17-ml4u-video3 %}) if you don't know what means). If you are anything like me, you might be apauled to be desconsidering all of unsupervised ande semi-supervised learning, but according to the paper it will make the maths easier (and we will be desconsidering so many other things, this will be the least of our worries).

More spefically, SLT theory tries to answer the following questions about learning tasks:

* Which learning tasks can machines perform? 
* To be able to garante that we can learn a task, what assumptions must we make about the task?
* For a machine learning algorithm to be able to learn a task, what proprierties does it need to have?
* Can we give any perfomance garantes to our ML algorithms?


# The formal setup

### Considerations about our data
To setup the framework we will use to help us answer some of the above questions, we will need to formalize some things:
Lets consider our data is divided into two parts, where X represents the information we have as to help us predict something (our feature space) and Y our prediction (target space).
Lets assume there is a underlying [joint probability distribution](http://www.inf.ed.ac.uk/teaching/courses/cfcs1/lectures/joint.pdf) $$ P $$ on $$ X \times Y $$ (that is, P is the distribution of the probability of X=x with intersection with Y=y or in mathematical jargom, $$ P(X=x | Y=y) $$). Also assume X and Y are [independent and identically distributed random variables (iid)](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables). That means that each instance of our data, $$ (X_i, Y_i) $$, is sampled independently from P, with one sampling not affecting the next.

We will be able to do many things with just these assumptions, but first lets have a look at what it truly means to suppose the things we did:

1. **We did not assume P to be any known distribution.** This is important because frequently in statistics we suppose certain distributions, but our whole work here won't actually try to define the distribution P

2. **Our labels can be non-deterministic.** Since P can be any distribution, we are including the case where we don't have a way to predict with 100% accuracy some instaces of our data. This can be seen from the fact that $$ P(X=x | Y=y) $$ does not need to be 0 or 1, instead being able to be any value in between as well. This is a needed property to have since we might have *noise* in our data, not allowing us to be 100% sure, or maybe we have *overlapping classes*.
For example consider we are trying to predict the sex of a individual given his height; depending on our data, it will be impossible to be 100% sure of the person's sex if their height is 1.7m (in fact, given a large enough sample, no height would give us 100% accuracy).
If there isn't much noise in the data, then $$ n(x) = P(X=x | Y=y) $$ will be either close to 0 or +1 (depending on if the true label of x is -1 or +1). But if there is a lot of noise in the data, $$ n(x) \approx 0.5 $$, which means that trying to predict the class is the same as a random guess.

3. **Independent sampling.** It is a reasonable assumption to make, but frequently not the case in real data. For example, take the drug pharmacy, where ML is used to try to predict if a certain combination of chemicals will be usefull for humans. Since it is very costly to actually test all of these combinations, the data we do have is based on what experts thought was worth testing in the first case, clearly not a independent sampling of all the possible chemical options.
We can also notice that this property means we can not use this framework (at least not without a more general formulation) to analyze [active learning](https://en.wikipedia.org/wiki/Active_learning_(machine_learning)).

4. **The distribution of P is fixed.** Because of this, we are excluding pretty much all time-series problems and problems related to co-variate shift, that is, when the distributions of independent variables change due to some variable we are not measuring (for example, the height of a population changing due to better access to food, but there still being a relationship between height and sex).

5. **The distribution of P is unknown.** This is important because we will learn that if P was known, we would have a closed formula for the best classifier. In ML, precisely what we want to solve are problems where P is not known.


Ok, that was a lot of thought provoking concepts, take some time to sketch them out and make sure you know what the implications of our assumptions really mean. With that done, let's now get into some more concrete definitions, which will be needed to help us evaluate how well a classifier performs:


### Definitions 
We will treat our classifier as a function/mapping of $$ X -> Y $$ and call it  $$ f $$.

We need a way to measure how a classifier performs, more especifically what is the error it makes on a single individual data point. The general name for this functions is a **loss function**. For example, in binary classification, our error can simply be 0 if we have predicted the right class and +1 otherwise. For regression problems, a frequently used loss function is the [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error). Given a certain classifier $$ f $$, our loss function is then: $$ L(X, Y, f(X)) $$.

So now that we have a function to measure the error of a instance in our data, what is our overall error? It can be defined as simply the [expected value](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/expected-value/) of the loss function, frequently callled the **risk of a function** and defined as $$ R(f) = E(L(X, Y, f(x)))$$, where $$ E() $$ represents the expected value of something.

With these definitions, we realize we want a classifier $$ f $$ that has the smallest possible $$ R(f) $$.


### A optimal classifier
Just remembering, we want a function $$ \{f: X - > Y\} $$ given a joint distribution P between X and Y. We can easily create a optimal classifier, named **Bayes Classifier** if we definite it as:

$$ f_{BAYES} = +1 $$     if $$ P(X=x \| Y=y) >= 0.5 $$

$$ f_{BAYES} = -1 $$       otherwise

That's great, if we can create such a classifier, all our problems are solved right? Actually, we have just created another problem: remember that the underlying distribution P is not known, therefore we can't actually create our classifier. Luckily for us, SLT comes to the rescue again! Let's first take a breather, get some coffee and properly define out classsification problem with all the definitions we have now created:


### Binary classification definition
Given some training points $$ (X_i, Y_i), ..., (X_n, Y_N) $$ drawn independently from some *unknown*, non-changing distribution P, and given a *loss function* $$ l() $$, how can we construct a function $$ f: X - > Y $$ which has a risk $$ R(f) $$ as close as possible to the risk of the Bayes Classifer?

That's good, we have now formalized exactly what the binary classification problem is! We an also know exactly what are problem is:

* We cannot compute $$ R(f_{BAYES}) $$ without knowing exactly what the distribution P is.

How does STL theory deal with this? As you've probably figured it out by now, by creating even more definitions and mathematical formalizations! Let's try to figure out what it means for a classifier to be able to "generalize" as well as the Bayes Classifier.


### Generalization and Consistency
Remember that we want a classifier *f* that is able to learn from data and generalize to some unseen data, but what does "generalize" even mean in this context? Intuitively it means that it makes the same mistakes the best possible classifier (Bayes Classifier) would make. We can write this out mathematically if we define the **empirical risk/training error** as:

$$ R_{emp}(f) = 1/n \sum_{i=1}^n l(X_i, Y_i, f(X_i)) $$




